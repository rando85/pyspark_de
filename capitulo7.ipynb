{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/12 21:10:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option('inferSchema', \"true\").csv('./data/Case.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |--  case_id: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- infection_case: string (nullable = true)\n",
      " |-- confirmed: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- infection_case: string (nullable = true)\n",
      " |-- confirmed: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\" case_id\", \"case_id\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+---------+\n",
      "|         province|           city|confirmed|\n",
      "+-----------------+---------------+---------+\n",
      "|            Seoul|        Guro-gu|       95|\n",
      "|Chungcheongnam-do|      Seosan-si|        9|\n",
      "| Gyeongsangnam-do|       Jinju-si|        9|\n",
      "|           Sejong|         Sejong|        8|\n",
      "| Gyeongsangnam-do|   Geochang-gun|        8|\n",
      "|            Seoul|     Gangnam-gu|        7|\n",
      "|            Seoul|        Jung-gu|        7|\n",
      "|            Seoul|      Jongno-gu|        7|\n",
      "|          Daejeon|         Seo-gu|        7|\n",
      "| Gyeongsangnam-do|    Changwon-si|        7|\n",
      "| Gyeongsangnam-do|Changnyeong-gun|        7|\n",
      "| Gyeongsangbuk-do|    Bonghwa-gun|       68|\n",
      "|      Gyeonggi-do|    Seongnam-si|       67|\n",
      "|      Gyeonggi-do|     Bucheon-si|       67|\n",
      "| Gyeongsangbuk-do|   Gyeongsan-si|       66|\n",
      "|            Seoul|     Gangnam-gu|        6|\n",
      "|            Seoul|   Geumcheon-gu|        6|\n",
      "|            Busan|    Haeundae-gu|        6|\n",
      "|      Gyeonggi-do|   Uijeongbu-si|       50|\n",
      "|            Busan|     Suyeong-gu|        5|\n",
      "+-----------------+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.select(col(\"province\"), col(\"city\"), col(\"confirmed\")).orderBy(col('confirmed').cast(\"int\").desc()).limit(3).show()\n",
    "\n",
    "df.select(col(\"province\"), col(\"city\"), col(\"confirmed\")).filter((col('city') != '-') & (col('city') != 'from other city')).orderBy(desc(col(\"confirmed\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.option(\"header\", \"true\").option('inferSchema', \"true\").csv('./data/PatientInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_id: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- infection_case: string (nullable = true)\n",
      " |-- infected_by: string (nullable = true)\n",
      " |-- contact_number: string (nullable = true)\n",
      " |-- symptom_onset_date: string (nullable = true)\n",
      " |-- confirmed_date: date (nullable = true)\n",
      " |-- released_date: date (nullable = true)\n",
      " |-- deceased_date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5164"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select(col('patient_id')).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropDuplicates([\"patient_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|conteo|\n",
      "+------+\n",
      "|  1346|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "#df2.filter(col(\"infected_by\").isNull()).count()\n",
    "df2.select(count('infected_by').alias('conteo')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_contagios = df2.na.drop(subset=['infected_by'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_contagios.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2_contagios.filter(col(\"infected_by\").isNull()).filter(col(\"sex\") == 'female')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|        city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "|1000000006|female|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|            43|              null|    2020-01-31|   2020-02-19|         null|released|\n",
      "|1000000007|  male|20s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|             0|              null|    2020-01-31|   2020-02-10|         null|released|\n",
      "|1000000008|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-02|   2020-02-24|         null|released|\n",
      "|1000000009|  male|30s|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|            68|              null|    2020-02-05|   2020-02-21|         null|released|\n",
      "|1000000010|female|60s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|             6|              null|    2020-02-05|   2020-02-29|         null|released|\n",
      "|1000000011|female|50s|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|            23|              null|    2020-02-06|   2020-02-29|         null|released|\n",
      "|1000000012|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-07|   2020-02-27|         null|released|\n",
      "|1000000013|  male|80s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|           117|              null|    2020-02-16|         null|         null|deceased|\n",
      "|1000000014|female|60s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|            27|        2020-02-06|    2020-02-16|   2020-03-12|         null|released|\n",
      "|1000000015|  male|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|             8|        2020-02-11|    2020-02-19|         null|         null|released|\n",
      "|1000000016|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|          null|              null|    2020-02-19|   2020-03-11|         null|released|\n",
      "|1000000017|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|          null|              null|    2020-02-20|   2020-03-01|         null|released|\n",
      "|1000000018|  male|20s|  Korea|   Seoul|         etc|                 etc|       null|          null|              null|    2020-02-20|         null|         null|released|\n",
      "|1000000019|female|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|          null|              null|    2020-02-20|   2020-03-08|         null|released|\n",
      "|1000000020|female|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|          null|              null|    2020-02-20|         null|         null|released|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#disminuyo a 2 \n",
    "df2.coalesce(2).write.partitionBy('province').mode('overwrite').parquet('./data/salida')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
